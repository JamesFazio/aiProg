{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from fractions import Fraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "folders = tf.io.gfile.glob(str('data/train/*/*'))\n",
    "folders.extend(tf.io.gfile.glob(str('data/val/*/*')))\n",
    "train, validate = train_test_split(folders, test_size=0.2)\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "val_data = tf.data.Dataset.from_tensor_slices(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 4108\n",
      "Validating images count: 1028\n",
      "Quotient of training images to validating images: 4\n"
     ]
    }
   ],
   "source": [
    "NORMAL = len([folder for folder in train if \"normal\" in folder])\n",
    "PNEUMONIA = len([folder for folder in train if \"opacity\" in folder])\n",
    "TRAINING_NUM = (NORMAL + PNEUMONIA)\n",
    "print(\"Number of training images: \" + str(TRAINING_NUM))\n",
    "\n",
    "VALIDATING_NUM = tf.data.experimental.cardinality(val_data).numpy()\n",
    "print(\"Validating images count: \" + str(VALIDATING_NUM))\n",
    "\n",
    "print(\"Quotient of training images to validating images: \" + str(Fraction(TRAINING_NUM / VALIDATING_NUM).limit_denominator(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the ratio for our image data is around 80:20 which is where we want it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERNAME = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n",
    "                        for item in tf.io.gfile.glob(str('data/train/*'))]) \n",
    "FOLDERNAME\n",
    "\n",
    "def get_name(file_path):\n",
    "    arr = tf.strings.split(file_path, os.path.sep)\n",
    "    return arr[-2] == \"opacity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to convert the images into 256x256 uint8 tensor. Also, since we are working with jpegs, we can use tensorflows dtype to convert its integer range that can go up to 255, down to a floating point max of 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = [256, 256]\n",
    "\n",
    "def convert_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float64)\n",
    "    return tf.image.resize(img, DIMENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access(file):\n",
    "    label = get_name(file)\n",
    "    img = tf.io.read_file(file)\n",
    "    img = convert_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train = train_data.map(access, num_parallel_calls=AUTOTUNE)\n",
    "val = val_data.map(access, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "testdata = tf.data.Dataset.list_files(str('data/test/*/*'))\n",
    "TESTING_NUM = tf.data.experimental.cardinality(testdata).numpy()\n",
    "test_data = testdata.map(access, num_parallel_calls=AUTOTUNE)\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "TESTING_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_for_training(train)\n",
    "val = prepare_for_training(val)\n",
    "image_batch, labeled_batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ]\n",
    "    )\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(DIMENSIONS[0], DIMENSIONS[1], 3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=EPOCHS)\n",
    "callbacks = [early_stop_callback]\n",
    "weight0 = (1 / NORMAL)*(TRAINING_NUM)/2.0 \n",
    "weight1 = (1 / PNEUMONIA)*(TRAINING_NUM)/2.0\n",
    "class_weight = {0: weight0, 1: weight1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "    METRICS = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 50/128 [==========>...................] - ETA: 2:41 - loss: 0.4654 - accuracy: 0.7756 - precision: 0.9471 - recall: 0.7436"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    steps_per_epoch = TRAINING_NUM // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data = val,\n",
    "    validation_steps = VALIDATING_NUM // BATCH_SIZE,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c700cc546fdf9d75b20a76139db37289074b9aa057030972da8bacd8c8bf116d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
